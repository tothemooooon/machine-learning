{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估和可视化工具\n",
    "\n",
    "## 概述\n",
    "本notebook提供了全面的神经网络模型评估和可视化工具，用于深入分析模型性能，包括：\n",
    "- 详细的性能指标分析\n",
    "- 多维度可视化展示\n",
    "- 错误案例深入分析\n",
    "- 模型对比和基准测试\n",
    "- 交互式可视化界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置样式\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"库导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 评估工具类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"神经网络模型评估器\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"Unknown Model\"):\n",
    "        self.model_name = model_name\n",
    "        self.evaluation_results = {}\n",
    "        self.predictions = None\n",
    "        self.probabilities = None\n",
    "        self.y_true = None\n",
    "        self.y_pred = None\n",
    "    \n",
    "    def evaluate(self, y_true, y_pred, y_pred_proba=None, X_test=None):\n",
    "        \"\"\"评估模型性能\"\"\"\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "        self.probabilities = y_pred_proba\n",
    "        \n",
    "        # 基础指标\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=None, zero_division=0\n",
    "        )\n",
    "        \n",
    "        # 宏平均和加权平均\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='macro', zero_division=0\n",
    "        )\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='weighted', zero_division=0\n",
    "        )\n",
    "        \n",
    "        # 混淆矩阵\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # 每个类别的准确率\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "        \n",
    "        # 存储结果\n",
    "        self.evaluation_results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision_per_class': precision,\n",
    "            'recall_per_class': recall,\n",
    "            'f1_per_class': f1,\n",
    "            'support_per_class': support,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'precision_weighted': precision_weighted,\n",
    "            'recall_weighted': recall_weighted,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'confusion_matrix': cm,\n",
    "            'class_accuracies': class_accuracies,\n",
    "            'classification_report': classification_report(y_true, y_pred, digits=4)\n",
    "        }\n",
    "        \n",
    "        # 如果提供了概率，计算AUC\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                # 对于多分类，需要二值化标签\n",
    "                y_true_bin = label_binarize(y_true, classes=range(10))\n",
    "                auc_scores = {}\n",
    "                \n",
    "                # 计算每个类别的AUC\n",
    "                for i in range(10):\n",
    "                    if len(np.unique(y_true_bin[:, i])) > 1:  # 确保有正负样本\n",
    "                        auc_scores[f'class_{i}'] = roc_auc_score(\n",
    "                            y_true_bin[:, i], y_pred_proba[:, i]\n",
    "                        )\n",
    "                \n",
    "                # 计算宏平均AUC\n",
    "                if auc_scores:\n",
    "                    auc_scores['macro_auc'] = np.mean(list(auc_scores.values()))\n",
    "                \n",
    "                self.evaluation_results['auc_scores'] = auc_scores\n",
    "            except Exception as e:\n",
    "                print(f\"AUC计算失败: {e}\")\n",
    "        \n",
    "        return self.evaluation_results\n",
    "    \n",
    "    def print_detailed_report(self):\n",
    "        \"\"\"打印详细的评估报告\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"              {self.model_name} - 详细评估报告\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\n【总体性能指标】\")\n",
    "        print(f\"  准确率 (Accuracy): {self.evaluation_results['accuracy']:.4f}\")\n",
    "        print(f\"  宏平均精确率 (Macro Precision): {self.evaluation_results['precision_macro']:.4f}\")\n",
    "        print(f\"  宏平均召回率 (Macro Recall): {self.evaluation_results['recall_macro']:.4f}\")\n",
    "        print(f\"  宏平均F1分数 (Macro F1): {self.evaluation_results['f1_macro']:.4f}\")\n",
    "        print(f\"  加权平均精确率 (Weighted Precision): {self.evaluation_results['precision_weighted']:.4f}\")\n",
    "        print(f\"  加权平均召回率 (Weighted Recall): {self.evaluation_results['recall_weighted']:.4f}\")\n",
    "        print(f\"  加权平均F1分数 (Weighted F1): {self.evaluation_results['f1_weighted']:.4f}\")\n",
    "        \n",
    "        # AUC分数\n",
    "        if 'auc_scores' in self.evaluation_results:\n",
    "            auc_scores = self.evaluation_results['auc_scores']\n",
    "            print(f\"\\n【AUC分数】\")\n",
    "            for key, value in auc_scores.items():\n",
    "                if key == 'macro_auc':\n",
    "                    print(f\"  宏平均AUC: {value:.4f}\")\n",
    "                else:\n",
    "                    class_num = key.split('_')[1]\n",
    "                    print(f\"  类别 {class_num}: {value:.4f}\")\n",
    "        \n",
    "        print(f\"\\n【各类别详细指标】\")\n",
    "        print(f\"{'类别':<6} {'精确率':<10} {'召回率':<10} {'F1分数':<10} {'准确率':<10} {'支持度':<8}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for i in range(10):\n",
    "            precision = self.evaluation_results['precision_per_class'][i]\n",
    "            recall = self.evaluation_results['recall_per_class'][i]\n",
    "            f1 = self.evaluation_results['f1_per_class'][i]\n",
    "            accuracy = self.evaluation_results['class_accuracies'][i]\n",
    "            support = self.evaluation_results['support_per_class'][i]\n",
    "            \n",
    "            print(f\"{i:<6} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {accuracy:<10.4f} {support:<8}\")\n",
    "        \n",
    "        print(f\"\\n【混淆矩阵分析】\")\n",
    "        cm = self.evaluation_results['confusion_matrix']\n",
    "        \n",
    "        # 找出最容易混淆的数字对\n",
    "        confusion_pairs = []\n",
    "        for i in range(10):\n",
    "            for j in range(10):\n",
    "                if i != j and cm[i, j] > 0:\n",
    "                    confusion_pairs.append((i, j, cm[i, j]))\n",
    "        \n",
    "        confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        print(f\"  最容易混淆的数字对:\")\n",
    "        for true_digit, pred_digit, count in confusion_pairs[:5]:\n",
    "            print(f\"    {true_digit} 被误认为 {pred_digit}: {count} 次\")\n",
    "        \n",
    "        # 类别难度分析\n",
    "        class_accuracies = self.evaluation_results['class_accuracies']\n",
    "        easiest_class = np.argmax(class_accuracies)\n",
    "        hardest_class = np.argmin(class_accuracies)\n",
    "        \n",
    "        print(f\"\\n  类别难度分析:\")\n",
    "        print(f\"    最容易识别: 数字 {easiest_class} (准确率: {class_accuracies[easiest_class]:.4f})\")\n",
    "        print(f\"    最难识别: 数字 {hardest_class} (准确率: {class_accuracies[hardest_class]:.4f})\")\n",
    "        \n",
    "        print(f\"\\n【详细分类报告】\")\n",
    "        print(self.evaluation_results['classification_report'])\n",
    "    \n",
    "    def create_comprehensive_visualization(self, figsize=(20, 15)):\n",
    "        \"\"\"创建综合的可视化报告\"\"\"\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. 混淆矩阵热力图\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        cm = self.evaluation_results['confusion_matrix']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                   xticklabels=range(10), yticklabels=range(10))\n",
    "        ax1.set_title('混淆矩阵')\n",
    "        ax1.set_xlabel('预测标签')\n",
    "        ax1.set_ylabel('真实标签')\n",
    "        \n",
    "        # 2. 各类别性能对比\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        metrics = ['精确率', '召回率', 'F1分数', '准确率']\n",
    "        x = np.arange(10)\n",
    "        width = 0.2\n",
    "        \n",
    "        for i, metric in enumerate(['precision_per_class', 'recall_per_class', \n",
    "                                   'f1_per_class', 'class_accuracies']):\n",
    "            values = self.evaluation_results[metric]\n",
    "            ax2.bar(x + i*width, values, width, label=metrics[i], alpha=0.8)\n",
    "        \n",
    "        ax2.set_xlabel('数字类别')\n",
    "        ax2.set_ylabel('分数')\n",
    "        ax2.set_title('各类别性能对比')\n",
    "        ax2.set_xticks(x + width * 1.5)\n",
    "        ax2.set_xticklabels(range(10))\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. 支持度分布\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        support = self.evaluation_results['support_per_class']\n",
    "        ax3.bar(range(10), support, color='skyblue', alpha=0.7)\n",
    "        ax3.set_xlabel('数字类别')\n",
    "        ax3.set_ylabel('样本数量')\n",
    "        ax3.set_title('各类别样本分布')\n",
    "        ax3.set_xticks(range(10))\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. 总体性能雷达图\n",
    "        ax4 = fig.add_subplot(gs[0, 3], projection='polar')\n",
    "        categories = ['准确率', '宏精确率', '宏召回率', '宏F1', '加权精确率', '加权召回率', '加权F1']\n",
    "        values = [\n",
    "            self.evaluation_results['accuracy'],\n",
    "            self.evaluation_results['precision_macro'],\n",
    "            self.evaluation_results['recall_macro'],\n",
    "            self.evaluation_results['f1_macro'],\n",
    "            self.evaluation_results['precision_weighted'],\n",
    "            self.evaluation_results['recall_weighted'],\n",
    "            self.evaluation_results['f1_weighted']\n",
    "        ]\n",
    "        \n",
    "        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "        values += values[:1]  # 闭合图形\n",
    "        angles += angles[:1]\n",
    "        \n",
    "        ax4.plot(angles, values, 'o-', linewidth=2)\n",
    "        ax4.fill(angles, values, alpha=0.25)\n",
    "        ax4.set_xticks(angles[:-1])\n",
    "        ax4.set_xticklabels(categories)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.set_title('总体性能雷达图')\n",
    "        \n",
    "        # 5. 错误分析热力图\n",
    "        ax5 = fig.add_subplot(gs[1, 0])\n",
    "        error_matrix = cm.copy()\n",
    "        np.fill_diagonal(error_matrix, 0)  # 将对角线设为0，只显示错误\n",
    "        \n",
    "        # 只显示有错误的单元格\n",
    "        mask = error_matrix == 0\n",
    "        sns.heatmap(error_matrix, annot=True, fmt='d', cmap='Reds', ax=ax5,\n",
    "                   xticklabels=range(10), yticklabels=range(10), mask=mask,\n",
    "                   cbar_kws={'label': '错误次数'})\n",
    "        ax5.set_title('错误分类热力图')\n",
    "        ax5.set_xlabel('预测标签')\n",
    "        ax5.set_ylabel('真实标签')\n",
    "        \n",
    "        # 6. 类别准确率排序\n",
    "        ax6 = fig.add_subplot(gs[1, 1])\n",
    "        class_accuracies = self.evaluation_results['class_accuracies']\n",
    "        sorted_indices = np.argsort(class_accuracies)[::-1]\n",
    "        sorted_accuracies = class_accuracies[sorted_indices]\n",
    "        sorted_labels = [f'数字 {i}' for i in sorted_indices]\n",
    "        \n",
    "        bars = ax6.barh(range(len(sorted_labels)), sorted_accuracies, color='lightgreen', alpha=0.7)\n",
    "        ax6.set_yticks(range(len(sorted_labels)))\n",
    "        ax6.set_yticklabels(sorted_labels)\n",
    "        ax6.set_xlabel('准确率')\n",
    "        ax6.set_title('各类别准确率排序')\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 添加数值标签\n",
    "        for i, (bar, acc) in enumerate(zip(bars, sorted_accuracies)):\n",
    "            ax6.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{acc:.3f}', ha='left', va='center')\n",
    "        \n",
    "        # 7. 精确率-召回率散点图\n",
    "        ax7 = fig.add_subplot(gs[1, 2])\n",
    "        precision = self.evaluation_results['precision_per_class']\n",
    "        recall = self.evaluation_results['recall_per_class']\n",
    "        \n",
    "        scatter = ax7.scatter(precision, recall, c=range(10), cmap='viridis', s=100, alpha=0.7)\n",
    "        ax7.set_xlabel('精确率')\n",
    "        ax7.set_ylabel('召回率')\n",
    "        ax7.set_title('精确率-召回率分布')\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 添加数字标签\n",
    "        for i in range(10):\n",
    "            ax7.annotate(str(i), (precision[i], recall[i]), \n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        # 添加平均线\n",
    "        ax7.axhline(y=recall.mean(), color='red', linestyle='--', alpha=0.5, label='平均召回率')\n",
    "        ax7.axvline(x=precision.mean(), color='blue', linestyle='--', alpha=0.5, label='平均精确率')\n",
    "        ax7.legend()\n",
    "        \n",
    "        # 8. F1分数分布\n",
    "        ax8 = fig.add_subplot(gs[1, 3])\n",
    "        f1_scores = self.evaluation_results['f1_per_class']\n",
    "        ax8.hist(f1_scores, bins=10, alpha=0.7, color='orange', edgecolor='black')\n",
    "        ax8.set_xlabel('F1分数')\n",
    "        ax8.set_ylabel('类别数量')\n",
    "        ax8.set_title('F1分数分布')\n",
    "        ax8.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 添加统计信息\n",
    "        ax8.axvline(x=f1_scores.mean(), color='red', linestyle='--', \n",
    "                   label=f'平均值: {f1_scores.mean():.3f}')\n",
    "        ax8.legend()\n",
    "        \n",
    "        # 9-12. 预留空间用于其他图表\n",
    "        ax9 = fig.add_subplot(gs[2, 0])\n",
    "        ax10 = fig.add_subplot(gs[2, 1])\n",
    "        ax11 = fig.add_subplot(gs[2, 2])\n",
    "        ax12 = fig.add_subplot(gs[2, 3])\n",
    "        \n",
    "        # 隐藏这些子图（可以后续添加更多可视化）\n",
    "        for ax in [ax9, ax10, ax11, ax12]:\n",
    "            ax.set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f'{self.model_name} - 综合评估报告', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def analyze_errors(self, X_test, top_n=20):\n",
    "        \"\"\"分析错误分类的样本\"\"\"\n",
    "        if self.y_true is None or self.y_pred is None:\n",
    "            print(\"请先运行evaluate方法\")\n",
    "            return\n",
    "        \n",
    "        # 找到错误分类的样本\n",
    "        errors = np.where(self.y_true != self.y_pred)[0]\n",
    "        \n",
    "        print(f\"\\n【错误分析报告】\")\n",
    "        print(f\"总错误样本数: {len(errors)}\")\n",
    "        print(f\"错误率: {len(errors) / len(self.y_true):.4f}\")\n",
    "        \n",
    "        if len(errors) == 0:\n",
    "            print(\"没有错误分类的样本！\")\n",
    "            return\n",
    "        \n",
    "        # 分析错误类型\n",
    "        error_analysis = {}\n",
    "        for idx in errors:\n",
    "            true_label = self.y_true[idx]\n",
    "            pred_label = self.y_pred[idx]\n",
    "            pair = (true_label, pred_label)\n",
    "            error_analysis[pair] = error_analysis.get(pair, 0) + 1\n",
    "        \n",
    "        # 排序错误类型\n",
    "        sorted_errors = sorted(error_analysis.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\n最常见的错误类型 (前10种):\")\n",
    "        for (true_label, pred_label), count in sorted_errors[:10]:\n",
    "            print(f\"  {true_label} → {pred_label}: {count} 次\")\n",
    "        \n",
    "        # 可视化错误样本\n",
    "        if X_test is not None:\n",
    "            self.visualize_error_samples(X_test, errors, top_n)\n",
    "        \n",
    "        return error_analysis\n",
    "    \n",
    "    def visualize_error_samples(self, X_test, error_indices, top_n=20):\n",
    "        \"\"\"可视化错误分类的样本\"\"\"\n",
    "        n_samples = min(top_n, len(error_indices))\n",
    "        selected_errors = np.random.choice(error_indices, n_samples, replace=False)\n",
    "        \n",
    "        rows = (n_samples + 4) // 5  # 每行5个图\n",
    "        fig, axes = plt.subplots(rows, 5, figsize=(15, 3*rows))\n",
    "        \n",
    "        if rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, idx in enumerate(selected_errors):\n",
    "            row = i // 5\n",
    "            col = i % 5\n",
    "            \n",
    "            # 显示图像\n",
    "            image = X_test[idx].reshape(28, 28)\n",
    "            axes[row, col].imshow(image, cmap='gray')\n",
    "            \n",
    "            # 添加标题\n",
    "            true_label = self.y_true[idx]\n",
    "            pred_label = self.y_pred[idx]\n",
    "            \n",
    "            # 如果有概率信息，显示置信度\n",
    "            title = f'真实: {true_label}, 预测: {pred_label}'\n",
    "            if self.probabilities is not None:\n",
    "                confidence = self.probabilities[idx, pred_label]\n",
    "                title += f'\\n置信度: {confidence:.3f}'\n",
    "            \n",
    "            axes[row, col].set_title(title, fontsize=10)\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        # 隐藏多余的子图\n",
    "        for i in range(n_samples, rows * 5):\n",
    "            row = i // 5\n",
    "            col = i % 5\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.suptitle('错误分类样本展示', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"ModelEvaluator类定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 可视化工具类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedVisualizer:\n",
    "    \"\"\"高级可视化工具类\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.color_palette = sns.color_palette(\"husl\", 10)\n",
    "    \n",
    "    def create_interactive_confusion_matrix(self, cm, class_names=None):\n",
    "        \"\"\"创建交互式混淆矩阵\"\"\"\n",
    "        if class_names is None:\n",
    "            class_names = [f'类别 {i}' for i in range(len(cm))]\n",
    "        \n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "            z=cm,\n",
    "            x=class_names,\n",
    "            y=class_names,\n",
    "            colorscale='Blues',\n",
    "            text=cm,\n",
    "            texttemplate=\"%{text}\",\n",
    "            textfont={\"size\": 12},\n",
    "            hoverongaps=False\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='交互式混淆矩阵',\n",
    "            xaxis_title='预测标签',\n",
    "            yaxis_title='真实标签',\n",
    "            width=600,\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_performance_comparison_chart(self, evaluators, evaluator_names):\n",
    "        \"\"\"创建多模型性能对比图表\"\"\"\n",
    "        metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "        metric_names = ['准确率', '宏精确率', '宏召回率', '宏F1']\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        for i, (evaluator, name) in enumerate(zip(evaluators, evaluator_names)):\n",
    "            values = [evaluator.evaluation_results[metric] for metric in metrics]\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=metric_names,\n",
    "                y=values,\n",
    "                mode='lines+markers',\n",
    "                name=name,\n",
    "                line=dict(width=3),\n",
    "                marker=dict(size=8)\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='多模型性能对比',\n",
    "            xaxis_title='评估指标',\n",
    "            yaxis_title='分数',\n",
    "            yaxis=dict(range=[0.8, 1.0]),\n",
    "            width=800,\n",
    "            height=500\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_class_performance_radar(self, evaluator):\n",
    "        \"\"\"创建各类别性能雷达图\"\"\"\n",
    "        precision = evaluator.evaluation_results['precision_per_class']\n",
    "        recall = evaluator.evaluation_results['recall_per_class']\n",
    "        f1 = evaluator.evaluation_results['f1_per_class']\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=5,\n",
    "            specs=[[{'type': 'polar'}] * 5] * 2,\n",
    "            subplot_titles=[f'数字 {i}' for i in range(10)]\n",
    "        )\n",
    "        \n",
    "        for i in range(10):\n",
    "            row = (i // 5) + 1\n",
    "            col = (i % 5) + 1\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatterpolar(\n",
    "                    r=[precision[i], recall[i], f1[i], precision[i]],\n",
    "                    theta=['精确率', '召回率', 'F1分数', '精确率'],\n",
    "                    fill='toself',\n",
    "                    name=f'数字 {i}'\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='各类别性能雷达图',\n",
    "            height=600,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_learning_curve_animation(self, histories, model_names):\n",
    "        \"\"\"创建学习曲线动画\"\"\"\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # 添加训练准确率曲线\n",
    "        for i, (history, name) in enumerate(zip(histories, model_names)):\n",
    "            epochs = list(range(len(history['train_accuracies'])))\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=epochs,\n",
    "                y=history['train_accuracies'],\n",
    "                mode='lines',\n",
    "                name=f'{name} - 训练',\n",
    "                line=dict(width=2),\n",
    "                visible=True if i == 0 else False\n",
    "            ))\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=epochs,\n",
    "                y=history['val_accuracies'],\n",
    "                mode='lines',\n",
    "                name=f'{name} - 验证',\n",
    "                line=dict(width=2, dash='dash'),\n",
    "                visible=True if i == 0 else False\n",
    "            ))\n",
    "        \n",
    "        # 创建动画按钮\n",
    "        buttons = []\n",
    "        for i, name in enumerate(model_names):\n",
    "            buttons.append(\n",
    "                dict(\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [j == i * 2 or j == i * 2 + 1 for j in range(len(model_names) * 2)]},\n",
    "                          {\"title\": f\"学习曲线 - {name}\"}],\n",
    "                    label=name\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            updatemenus=[dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"right\",\n",
    "                x=0.1,\n",
    "                y=1.02,\n",
    "                showactive=True,\n",
    "                buttons=buttons\n",
    "            )],\n",
    "            title=\"学习曲线对比\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=\"准确率\",\n",
    "            width=800,\n",
    "            height=500\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_prediction_confidence_analysis(self, y_true, y_pred_proba, y_pred):\n",
    "        \"\"\"创建预测置信度分析\"\"\"\n",
    "        # 计算每个预测的置信度\n",
    "        confidences = np.max(y_pred_proba, axis=1)\n",
    "        \n",
    "        # 分离正确和错误预测的置信度\n",
    "        correct_mask = y_true == y_pred\n",
    "        correct_confidences = confidences[correct_mask]\n",
    "        incorrect_confidences = confidences[~correct_mask]\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['置信度分布', '置信度 vs 准确性', '各类别置信度', '低置信度样本']\n",
    "        )\n",
    "        \n",
    "        # 1. 置信度分布直方图\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=correct_confidences,\n",
    "                name='正确预测',\n",
    "                opacity=0.7,\n",
    "                marker_color='green',\n",
    "                nbinsx=20\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=incorrect_confidences,\n",
    "                name='错误预测',\n",
    "                opacity=0.7,\n",
    "                marker_color='red',\n",
    "                nbinsx=20\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # 2. 置信度 vs 准确性散点图\n",
    "        accuracy_threshold = np.linspace(0, 1, 20)\n",
    "        accuracy_by_confidence = []\n",
    "        \n",
    "        for threshold in accuracy_threshold:\n",
    "            mask = confidences >= threshold\n",
    "            if mask.sum() > 0:\n",
    "                accuracy = np.mean(y_true[mask] == y_pred[mask])\n",
    "                accuracy_by_confidence.append(accuracy)\n",
    "            else:\n",
    "                accuracy_by_confidence.append(0)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=accuracy_threshold,\n",
    "                y=accuracy_by_confidence,\n",
    "                mode='lines+markers',\n",
    "                name='准确率',\n",
    "                line=dict(width=3)\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # 3. 各类别置信度箱线图\n",
    "        class_confidences = []\n",
    "        for digit in range(10):\n",
    "            mask = y_true == digit\n",
    "            class_confidences.append(confidences[mask])\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=class_confidences,\n",
    "                name='置信度分布',\n",
    "                boxpoints='outliers'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # 4. 低置信度样本统计\n",
    "        low_confidence_threshold = 0.5\n",
    "        low_confidence_mask = confidences < low_confidence_threshold\n",
    "        low_confidence_accuracy = np.mean(y_true[low_confidence_mask] == y_pred[low_confidence_mask])\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=['所有样本', f'低置信度(<{low_confidence_threshold})'],\n",
    "                y=[np.mean(y_true == y_pred), low_confidence_accuracy],\n",
    "                name='准确率',\n",
    "                marker_color=['blue', 'orange']\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='预测置信度分析',\n",
    "            height=800,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        # 更新坐标轴标签\n",
    "        fig.update_xaxes(title_text=\"置信度\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"频次\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"置信度阈值\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"准确率\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"数字类别\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"置信度\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"准确率\", row=2, col=2)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "print(\"AdvancedVisualizer类定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 示例数据加载和模型评估演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data():\n",
    "    \"\"\"加载示例数据用于演示\"\"\"\n",
    "    print(\"正在加载示例数据...\")\n",
    "    \n",
    "    # 从sklearn加载MNIST数据\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    X, y = mnist.data, mnist.target.astype(int)\n",
    "    \n",
    "    # 数据预处理\n",
    "    X = X.astype('float32') / 255.0\n",
    "    \n",
    "    # 分割数据（只使用小样本进行演示）\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # 进一步减小测试集用于演示\n",
    "    X_test_demo = X_test[:1000]\n",
    "    y_test_demo = y_test[:1000]\n",
    "    \n",
    "    print(f\"演示数据集大小: {X_test_demo.shape}\")\n",
    "    print(f\"标签分布: {np.bincount(y_test_demo)}\")\n",
    "    \n",
    "    return X_test_demo, y_test_demo\n",
    "\n",
    "def create_mock_predictions(X_test, y_test):\n",
    "    \"\"\"创建模拟的预测结果用于演示\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 创建模拟预测（90%准确率）\n",
    "    y_pred = y_test.copy()\n",
    "    n_errors = int(len(y_test) * 0.1)  # 10%错误率\n",
    "    error_indices = np.random.choice(len(y_test), n_errors, replace=False)\n",
    "    \n",
    "    # 为错误样本生成随机预测\n",
    "    for idx in error_indices:\n",
    "        available_classes = [i for i in range(10) if i != y_test[idx]]\n",
    "        y_pred[idx] = np.random.choice(available_classes)\n",
    "    \n",
    "    # 创建模拟概率\n",
    "    y_pred_proba = np.random.dirichlet(np.ones(10), size=len(y_test))\n",
    "    \n",
    "    # 调整概率使预测类别有最高概率\n",
    "    for i in range(len(y_test)):\n",
    "        y_pred_proba[i, y_pred[i]] = np.max(y_pred_proba[i, :]) * 1.5\n",
    "        y_pred_proba[i] = y_pred_proba[i] / y_pred_proba[i].sum()\n",
    "    \n",
    "    print(f\"模拟预测准确率: {np.mean(y_pred == y_test):.4f}\")\n",
    "    \n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "# 加载示例数据\n",
    "X_demo, y_demo = load_sample_data()\n",
    "y_pred_demo, y_pred_proba_demo = create_mock_predictions(X_demo, y_demo)\n",
    "\n",
    "print(\"\\n示例数据准备完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 评估工具演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建评估器\n",
    "evaluator = ModelEvaluator(\"演示模型\")\n",
    "\n",
    "# 评估模型\n",
    "results = evaluator.evaluate(y_demo, y_pred_demo, y_pred_proba_demo, X_demo)\n",
    "\n",
    "# 打印详细报告\n",
    "evaluator.print_detailed_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 综合可视化演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建综合可视化\n",
    "evaluator.create_comprehensive_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 错误分析演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析错误\n",
    "error_analysis = evaluator.analyze_errors(X_demo, top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 高级可视化演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建高级可视化器\n",
    "visualizer = AdvancedVisualizer()\n",
    "\n",
    "# 1. 交互式混淆矩阵\n",
    "interactive_cm = visualizer.create_interactive_confusion_matrix(\n",
    "    evaluator.evaluation_results['confusion_matrix']\n",
    ")\n",
    "interactive_cm.show()\n",
    "\n",
    "# 2. 性能雷达图\n",
    "performance_radar = visualizer.create_class_performance_radar(evaluator)\n",
    "performance_radar.show()\n",
    "\n",
    "# 3. 置信度分析\n",
    "confidence_analysis = visualizer.create_prediction_confidence_analysis(\n",
    "    y_demo, y_pred_proba_demo, y_pred_demo\n",
    ")\n",
    "confidence_analysis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 多模型对比演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_mock_models(X_test, y_test, n_models=3):\n",
    "    \"\"\"创建多个模拟模型用于对比\"\"\"\n",
    "    evaluators = []\n",
    "    model_names = []\n",
    "    \n",
    "    # 不同的准确率水平\n",
    "    accuracy_levels = [0.85, 0.90, 0.95]\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        np.random.seed(42 + i)  # 不同的随机种子\n",
    "        \n",
    "        # 创建模拟预测\n",
    "        y_pred = y_test.copy()\n",
    "        target_accuracy = accuracy_levels[i]\n",
    "        n_errors = int(len(y_test) * (1 - target_accuracy))\n",
    "        error_indices = np.random.choice(len(y_test), n_errors, replace=False)\n",
    "        \n",
    "        for idx in error_indices:\n",
    "            available_classes = [j for j in range(10) if j != y_test[idx]]\n",
    "            y_pred[idx] = np.random.choice(available_classes)\n",
    "        \n",
    "        # 创建概率\n",
    "        y_pred_proba = np.random.dirichlet(np.ones(10), size=len(y_test))\n",
    "        for j in range(len(y_test)):\n",
    "            y_pred_proba[j, y_pred[j]] = np.max(y_pred_proba[j, :]) * 1.5\n",
    "            y_pred_proba[j] = y_pred_proba[j] / y_pred_proba[j].sum()\n",
    "        \n",
    "        # 创建评估器\n",
    "        evaluator = ModelEvaluator(f\"模型 {i+1} (准确率: {target_accuracy:.2f})\")\n",
    "        evaluator.evaluate(y_test, y_pred, y_pred_proba_demo)\n",
    "        \n",
    "        evaluators.append(evaluator)\n",
    "        model_names.append(f\"模型 {i+1}\")\n",
    "        \n",
    "        print(f\"{model_names[-1]}: 实际准确率 = {np.mean(y_pred == y_test):.4f}\")\n",
    "    \n",
    "    return evaluators, model_names\n",
    "\n",
    "# 创建多个模拟模型\n",
    "evaluators, model_names = create_multiple_mock_models(X_demo, y_demo)\n",
    "\n",
    "# 创建性能对比图表\n",
    "comparison_chart = visualizer.create_performance_comparison_chart(evaluators, model_names)\n",
    "comparison_chart.show()\n",
    "\n",
    "# 创建对比报告\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                    多模型性能对比报告\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"{'模型':<20} {'准确率':<10} {'宏F1':<10} {'加权F1':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for evaluator, name in zip(evaluators, model_names):\n",
    "    accuracy = evaluator.evaluation_results['accuracy']\n",
    "    f1_macro = evaluator.evaluation_results['f1_macro']\n",
    "    f1_weighted = evaluator.evaluation_results['f1_weighted']\n",
    "    \n",
    "    print(f\"{name:<20} {accuracy:<10.4f} {f1_macro:<10.4f} {f1_weighted:<10.4f}\")\n",
    "\n",
    "# 找出最佳模型\n",
    "best_idx = np.argmax([eval.evaluation_results['accuracy'] for eval in evaluators])\n",
    "print(f\"\\n最佳模型: {model_names[best_idx]}\")\n",
    "print(f\"最高准确率: {evaluators[best_idx].evaluation_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 实用工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_report(evaluator, save_path=None):\n",
    "    \"\"\"生成完整的评估报告\"\"\"\n",
    "    report = []\n",
    "    \n",
    "    report.append(\"# 神经网络模型评估报告\")\n",
    "    report.append(f\"\\n## 模型名称: {evaluator.model_name}\")\n",
    "    report.append(f\"\\n生成时间: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # 总体性能\n",
    "    report.append(\"\\n## 总体性能指标\")\n",
    "    report.append(f\"- **准确率**: {evaluator.evaluation_results['accuracy']:.4f}\")\n",
    "    report.append(f\"- **宏平均精确率**: {evaluator.evaluation_results['precision_macro']:.4f}\")\n",
    "    report.append(f\"- **宏平均召回率**: {evaluator.evaluation_results['recall_macro']:.4f}\")\n",
    "    report.append(f\"- **宏平均F1分数**: {evaluator.evaluation_results['f1_macro']:.4f}\")\n",
    "    report.append(f\"- **加权平均精确率**: {evaluator.evaluation_results['precision_weighted']:.4f}\")\n",
    "    report.append(f\"- **加权平均召回率**: {evaluator.evaluation_results['recall_weighted']:.4f}\")\n",
    "    report.append(f\"- **加权平均F1分数**: {evaluator.evaluation_results['f1_weighted']:.4f}\")\n",
    "    \n",
    "    # 各类别详细指标\n",
    "    report.append(\"\\n## 各类别详细指标\")\n",
    "    report.append(\"| 类别 | 精确率 | 召回率 | F1分数 | 准确率 | 支持度 |\")\n",
    "    report.append(\"|------|--------|--------|--------|--------|--------|\")\n",
    "    \n",
    "    for i in range(10):\n",
    "        precision = evaluator.evaluation_results['precision_per_class'][i]\n",
    "        recall = evaluator.evaluation_results['recall_per_class'][i]\n",
    "        f1 = evaluator.evaluation_results['f1_per_class'][i]\n",
    "        accuracy = evaluator.evaluation_results['class_accuracies'][i]\n",
    "        support = evaluator.evaluation_results['support_per_class'][i]\n",
    "        \n",
    "        report.append(f\"| {i} | {precision:.4f} | {recall:.4f} | {f1:.4f} | {accuracy:.4f} | {support} |\")\n",
    "    \n",
    "    # 分析和建议\n",
    "    report.append(\"\\n## 分析和建议\")\n",
    "    \n",
    "    class_accuracies = evaluator.evaluation_results['class_accuracies']\n",
    "    easiest_class = np.argmax(class_accuracies)\n",
    "    hardest_class = np.argmin(class_accuracies)\n",
    "    \n",
    "    report.append(f\"\\n### 性能分析\")\n",
    "    report.append(f\"- **最容易识别的数字**: {easiest_class} (准确率: {class_accuracies[easiest_class]:.4f})\")\n",
    "    report.append(f\"- **最难识别的数字**: {hardest_class} (准确率: {class_accuracies[hardest_class]:.4f})\")\n",
    "    report.append(f\"- **性能差异**: {class_accuracies[easiest_class] - class_accuracies[hardest_class]:.4f}\")\n",
    "    \n",
    "    # 改进建议\n",
    "    report.append(\"\\n### 改进建议\")\n",
    "    \n",
    "    if evaluator.evaluation_results['accuracy'] < 0.95:\n",
    "        report.append(\"- **准确率偏低**: 建议增加网络深度或宽度\")\n",
    "        report.append(\"- **数据增强**: 考虑使用旋转、平移等数据增强技术\")\n",
    "    \n",
    "    if np.std(class_accuracies) > 0.05:\n",
    "        report.append(\"- **类别不平衡**: 某些类别性能较差，需要针对性优化\")\n",
    "        report.append(\"- **错误分析**: 重点分析难识别类别的错误模式\")\n",
    "    \n",
    "    report.append(\"- **超参数调优**: 尝试不同的学习率和批次大小\")\n",
    "    report.append(\"- **正则化**: 考虑添加Dropout或L2正则化防止过拟合\")\n",
    "    \n",
    "    # 生成报告文本\n",
    "    report_text = \"\\n\".join(report)\n",
    "    \n",
    "    # 保存报告\n",
    "    if save_path:\n",
    "        with open(save_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_text)\n",
    "        print(f\"评估报告已保存到: {save_path}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "def compare_models_detailed(evaluators, model_names):\n",
    "    \"\"\"详细对比多个模型\"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"                         详细模型对比分析\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # 创建对比表格\n",
    "    metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "    metric_names = ['准确率', '宏精确率', '宏召回率', '宏F1']\n",
    "    \n",
    "    print(f\"{'模型':<20} {'总体准确率':<12} {'宏精确率':<12} {'宏召回率':<12} {'宏F1':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for evaluator, name in zip(evaluators, model_names):\n",
    "        values = [evaluator.evaluation_results[metric] for metric in metrics]\n",
    "        print(f\"{name:<20} {values[0]:<12.4f} {values[1]:<12.4f} {values[2]:<12.4f} {values[3]:<12.4f}\")\n",
    "    \n",
    "    # 各类别最佳模型\n",
    "    print(f\"\\n【各类别最佳模型】\")\n",
    "    print(f\"{'类别':<6}\", end=\"\")\n",
    "    for name in model_names:\n",
    "        print(f\"{name:<15}\", end=\"\")\n",
    "    print(\"最佳模型\")\n",
    "    print(\"-\" * (6 + 15 * len(model_names) + 10))\n",
    "    \n",
    "    for digit in range(10):\n",
    "        print(f\"{digit:<6}\", end=\"\")\n",
    "        best_accuracy = 0\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for evaluator, name in zip(evaluators, model_names):\n",
    "            accuracy = evaluator.evaluation_results['class_accuracies'][digit]\n",
    "            print(f\"{accuracy:<15.4f}\", end=\"\")\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = name\n",
    "        \n",
    "        print(f\"{best_model}\")\n",
    "    \n",
    "    # 统计显著性测试（简化版）\n",
    "    print(f\"\\n【性能排名】\")\n",
    "    rankings = {}\n",
    "    \n",
    "    for metric, metric_name in zip(metrics, metric_names):\n",
    "        scores = [eval.evaluation_results[metric] for eval in evaluators]\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        \n",
    "        print(f\"\\n{metric_name}排名:\")\n",
    "        for rank, idx in enumerate(sorted_indices, 1):\n",
    "            print(f\"  {rank}. {model_names[idx]}: {scores[idx]:.4f}\")\n",
    "        \n",
    "        rankings[metric] = sorted_indices\n",
    "    \n",
    "    # 综合排名\n",
    "    print(f\"\\n【综合排名】(基于4个指标的平均排名)\")\n",
    "    avg_ranks = []\n",
    "    \n",
    "    for i in range(len(evaluators)):\n",
    "        avg_rank = np.mean([list(ranks).index(i) + 1 for ranks in rankings.values()])\n",
    "        avg_ranks.append(avg_rank)\n",
    "    \n",
    "    final_ranking = np.argsort(avg_ranks)\n",
    "    \n",
    "    for rank, idx in enumerate(final_ranking, 1):\n",
    "        print(f\"  {rank}. {model_names[idx]}: 平均排名 {avg_ranks[idx]:.2f}\")\n",
    "\n",
    "# 生成评估报告\n",
    "report = generate_evaluation_report(evaluator)\n",
    "print(report)\n",
    "\n",
    "# 如果有多个模型，进行详细对比\n",
    "if len(evaluators) > 1:\n",
    "    compare_models_detailed(evaluators, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 总结和使用指南"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_usage_guide():\n",
    "    \"\"\"打印使用指南\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"                模型评估和可视化工具 - 使用指南\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n【基本使用流程】\")\n",
    "    steps = [\n",
    "        \"1. 创建评估器: evaluator = ModelEvaluator('模型名称')\",\n",
    "        \"2. 评估模型: results = evaluator.evaluate(y_true, y_pred, y_pred_proba, X_test)\",\n",
    "        \"3. 查看报告: evaluator.print_detailed_report()\",\n",
    "        \"4. 可视化: evaluator.create_comprehensive_visualization()\",\n",
    "        \"5. 错误分析: evaluator.analyze_errors(X_test)\"\n",
    "    ]\n",
    "    \n",
    "    for step in steps:\n",
    "        print(f\"  {step}\")\n",
    "    \n",
    "    print(\"\\n【高级可视化】\")\n",
    "    advanced_features = [\n",
    "        \"• 交互式混淆矩阵: visualizer.create_interactive_confusion_matrix()\",\n",
    "        \"• 多模型性能对比: visualizer.create_performance_comparison_chart()\",\n",
    "        \"• 类别性能雷达图: visualizer.create_class_performance_radar()\",\n",
    "        \"• 学习曲线动画: visualizer.create_learning_curve_animation()\",\n",
    "        \"• 预测置信度分析: visualizer.create_prediction_confidence_analysis()\"\n",
    "    ]\n",
    "    \n",
    "    for feature in advanced_features:\n",
    "        print(f\"  {feature}\")\n",
    "    \n",
    "    print(\"\\n【实用工具】\")\n",
    "    tools = [\n",
    "        \"• 生成报告: generate_evaluation_report(evaluator, '报告.md')\",\n",
    "        \"• 模型对比: compare_models_detailed(evaluators, model_names)\",\n",
    "        \"• 批量评估: 支持同时评估多个模型\",\n",
    "        \"• 结果导出: 支持保存可视化结果和评估报告\"\n",
    "    ]\n",
    "    \n",
    "    for tool in tools:\n",
    "        print(f\"  {tool}\")\n",
    "    \n",
    "    print(\"\\n【输入数据要求】\")\n",
    "    requirements = [\n",
    "        \"• y_true: 真实标签 (numpy数组)\",\n",
    "        \"• y_pred: 预测标签 (numpy数组)\",\n",
    "        \"• y_pred_proba: 预测概率 (numpy数组, 可选)\",\n",
    "        \"• X_test: 测试数据 (用于错误分析, 可选)\"\n",
    "    ]\n",
    "    \n",
    "    for req in requirements:\n",
    "        print(f\"  {req}\")\n",
    "    \n",
    "    print(\"\\n【扩展功能】\")\n",
    "    extensions = [\n",
    "        \"• 支持多分类和二分类问题\",\n",
    "        \"• 自定义可视化样式和颜色\",\n",
    "        \"• 集成到Jupyter Notebook或Web应用\",\n",
    "        \"• 支持大规模数据集的高效处理\",\n",
    "        \"• 可扩展的评估指标体系\"\n",
    "    ]\n",
    "    \n",
    "    for ext in extensions:\n",
    "        print(f\"  {ext}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"感谢使用模型评估和可视化工具！\")\n",
    "    print(\"这些工具可以帮助您全面分析和展示神经网络模型的性能。\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# 显示使用指南\n",
    "print_usage_guide()\n",
    "\n",
    "print(\"\\n模型评估和可视化工具演示完成！\")\n",
    "print(\"主要功能:\")\n",
    "print(\"1. 全面的性能指标评估\")\n",
    "print(\"2. 丰富的可视化图表\")\n",
    "print(\"3. 深入的错误分析\")\n",
    "print(\"4. 多模型对比分析\")\n",
    "print(\"5. 交互式可视化界面\")\n",
    "print(\"6. 自动报告生成\")\n",
    "print(\"\\n这些工具可以应用于任何分类模型的评估，不限于数字识别任务。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}