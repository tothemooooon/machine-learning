{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标准库对比实现 - TensorFlow/Keras神经网络\n",
    "\n",
    "## 概述\n",
    "本notebook使用TensorFlow/Keras框架实现神经网络，与手写实现进行对比分析。我们将探索深度学习框架的优势，包括：\n",
    "- 更简洁的API\n",
    "- 更高效的计算\n",
    "- 更丰富的功能\n",
    "- 更好的性能优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入深度学习框架和其他必要库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# TensorFlow/Keras导入\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers, models, optimizers, losses, metrics, callbacks\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "    TF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow未安装，将使用模拟实现\")\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "# PyTorch作为备选\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    print(f\"PyTorch版本: {torch.__version__}\")\n",
    "    PYTORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"PyTorch未安装\")\n",
    "    PYTORCH_AVAILABLE = False\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"库导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据准备和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"加载和预处理MNIST数据\"\"\"\n",
    "    print(\"正在加载MNIST数据集...\")\n",
    "    \n",
    "    # 从sklearn加载MNIST数据\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    X, y = mnist.data, mnist.target.astype(int)\n",
    "    \n",
    "    print(f\"原始数据形状: X={X.shape}, y={y.shape}\")\n",
    "    \n",
    "    # 数据标准化\n",
    "    X = X.astype('float32') / 255.0\n",
    "    \n",
    "    # 分割数据集\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp\n",
    "    )  # 0.125 * 0.8 = 0.1 overall\n",
    "    \n",
    "    print(f\"数据分割:\")\n",
    "    print(f\"  训练集: {X_train.shape}\")\n",
    "    print(f\"  验证集: {X_val.shape}\")\n",
    "    print(f\"  测试集: {X_test.shape}\")\n",
    "    \n",
    "    # 为不同的框架准备数据\n",
    "    data = {\n",
    "        'X_train': X_train, 'X_val': X_val, 'X_test': X_test,\n",
    "        'y_train': y_train, 'y_val': y_val, 'y_test': y_test\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 加载数据\n",
    "data = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow/Keras实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_AVAILABLE:\n",
    "    def create_tf_model(input_shape=(784,), num_classes=10, hidden_layers=[256, 128]):\n",
    "        \"\"\"使用TensorFlow/Keras创建神经网络模型\"\"\"\n",
    "        model = models.Sequential()\n",
    "        \n",
    "        # 输入层\n",
    "        model.add(layers.Input(shape=input_shape))\n",
    "        \n",
    "        # 隐藏层\n",
    "        for i, units in enumerate(hidden_layers):\n",
    "            model.add(layers.Dense(units, activation='relu', name=f'hidden_{i+1}'))\n",
    "            model.add(layers.Dropout(0.2, name=f'dropout_{i+1}'))  # 添加Dropout防止过拟合\n",
    "        \n",
    "        # 输出层\n",
    "        model.add(layers.Dense(num_classes, activation='softmax', name='output'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def compile_and_train_tf_model(model, data, epochs=50, batch_size=64, learning_rate=0.001):\n",
    "        \"\"\"编译和训练TensorFlow模型\"\"\"\n",
    "        # 编译模型\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # 设置回调函数\n",
    "        callbacks_list = [\n",
    "            callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 训练模型\n",
    "        start_time = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            data['X_train'], data['y_train'],\n",
    "            validation_data=(data['X_val'], data['y_val']),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"训练完成，用时: {training_time:.2f}秒\")\n",
    "        \n",
    "        return model, history, training_time\n",
    "    \n",
    "    def evaluate_tf_model(model, data):\n",
    "        \"\"\"评估TensorFlow模型\"\"\"\n",
    "        # 在测试集上评估\n",
    "        test_loss, test_accuracy = model.evaluate(data['X_test'], data['y_test'], verbose=0)\n",
    "        \n",
    "        # 预测\n",
    "        y_pred_proba = model.predict(data['X_test'])\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    # 创建和训练TensorFlow模型\n",
    "    print(\"=== TensorFlow/Keras实现 ===\")\n",
    "    tf_model = create_tf_model()\n",
    "    tf_model.summary()\n",
    "    \n",
    "    tf_trained_model, tf_history, tf_training_time = compile_and_train_tf_model(tf_model, data)\n",
    "    tf_results = evaluate_tf_model(tf_trained_model, data)\n",
    "    \n",
    "    print(f\"\\nTensorFlow模型结果:\")\n",
    "    print(f\"  测试准确率: {tf_results['test_accuracy']:.4f}\")\n",
    "    print(f\"  测试损失: {tf_results['test_loss']:.4f}\")\n",
    "    print(f\"  训练时间: {tf_training_time:.2f}秒\")\n",
    "else:\n",
    "    print(\"TensorFlow不可用，跳过TensorFlow实现\")\n",
    "    tf_model = None\n",
    "    tf_history = None\n",
    "    tf_results = None\n",
    "    tf_training_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PyTorch实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYTORCH_AVAILABLE:\n",
    "    class PyTorchNN(nn.Module):\n",
    "        \"\"\"PyTorch神经网络定义\"\"\"\n",
    "        def __init__(self, input_size=784, hidden_sizes=[256, 128], num_classes=10, dropout_rate=0.2):\n",
    "            super(PyTorchNN, self).__init__()\n",
    "            \n",
    "            layers = []\n",
    "            \n",
    "            # 输入层到第一个隐藏层\n",
    "            layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "            # 隐藏层之间\n",
    "            for i in range(len(hidden_sizes) - 1):\n",
    "                layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "            # 最后一个隐藏层到输出层\n",
    "            layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
    "            \n",
    "            self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "    \n",
    "    def train_pytorch_model(model, data, epochs=50, batch_size=64, learning_rate=0.001):\n",
    "        \"\"\"训练PyTorch模型\"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        \n",
    "        # 准备数据加载器\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.FloatTensor(data['X_train']),\n",
    "            torch.LongTensor(data['y_train'])\n",
    "        )\n",
    "        val_dataset = TensorDataset(\n",
    "            torch.FloatTensor(data['X_val']),\n",
    "            torch.LongTensor(data['y_val'])\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 定义损失函数和优化器\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # 训练循环\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_total += batch_y.size(0)\n",
    "                train_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            # 验证阶段\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += batch_y.size(0)\n",
    "                    val_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            # 计算平均损失和准确率\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            train_accuracy = train_correct / train_total\n",
    "            val_accuracy = val_correct / val_total\n",
    "            \n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            \n",
    "            # 学习率调度\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # 早停\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= 10:\n",
    "                print(f\"早停于epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}: \")\n",
    "                print(f\"  训练损失: {avg_train_loss:.4f}, 训练准确率: {train_accuracy:.4f}\")\n",
    "                print(f\"  验证损失: {avg_val_loss:.4f}, 验证准确率: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # 加载最佳模型\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"训练完成，用时: {training_time:.2f}秒\")\n",
    "        \n",
    "        history = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies\n",
    "        }\n",
    "        \n",
    "        return model, history, training_time\n",
    "    \n",
    "    def evaluate_pytorch_model(model, data):\n",
    "        \"\"\"评估PyTorch模型\"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        test_dataset = TensorDataset(\n",
    "            torch.FloatTensor(data['X_test']),\n",
    "            torch.LongTensor(data['y_test'])\n",
    "        )\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        accuracy = np.mean(np.array(all_predictions) == data['y_test'])\n",
    "        \n",
    "        return {\n",
    "            'test_loss': avg_loss,\n",
    "            'test_accuracy': accuracy,\n",
    "            'y_pred': np.array(all_predictions),\n",
    "            'y_pred_proba': np.array(all_probabilities)\n",
    "        }\n",
    "    \n",
    "    # 创建和训练PyTorch模型\n",
    "    print(\"\\n=== PyTorch实现 ===\")\n",
    "    pytorch_model = PyTorchNN()\n",
    "    print(f\"PyTorch模型结构:\")\n",
    "    print(pytorch_model)\n",
    "    \n",
    "    pytorch_trained_model, pytorch_history, pytorch_training_time = train_pytorch_model(pytorch_model, data)\n",
    "    pytorch_results = evaluate_pytorch_model(pytorch_trained_model, data)\n",
    "    \n",
    "    print(f\"\\nPyTorch模型结果:\")\n",
    "    print(f\"  测试准确率: {pytorch_results['test_accuracy']:.4f}\")\n",
    "    print(f\"  测试损失: {pytorch_results['test_loss']:.4f}\")\n",
    "    print(f\"  训练时间: {pytorch_training_time:.2f}秒\")\n",
    "else:\n",
    "    print(\"PyTorch不可用，跳过PyTorch实现\")\n",
    "    pytorch_model = None\n",
    "    pytorch_history = None\n",
    "    pytorch_results = None\n",
    "    pytorch_training_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模拟标准库实现（用于对比）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果深度学习框架不可用，提供一个模拟的高性能实现\ndef create_simulated_framework_implementation(data):\n",
    "    \"\"\"模拟深度学习框架的高性能实现\"\"\"\n",
    "    print(\"=== 模拟标准库实现 ===\")\n",
    "    \n",
    "    class OptimizedNeuralNetwork:\n",
    "        \"\"\"优化的神经网络实现（模拟标准库性能）\"\"\"\n",
    "        def __init__(self, layer_sizes=[784, 256, 128, 10]):\n",
    "            self.layer_sizes = layer_sizes\n",
    "            self.weights = []\n",
    "            self.biases = []\n",
    "            \n",
    "            # 使用更好的初始化方法\n",
    "            for i in range(len(layer_sizes) - 1):\n",
    "                # He初始化\n",
    "                limit = np.sqrt(6 / layer_sizes[i]) * 2\n",
    "                W = np.random.uniform(-limit, limit, (layer_sizes[i], layer_sizes[i+1]))\n",
    "                b = np.zeros((1, layer_sizes[i+1]))\n",
    "                self.weights.append(W)\n",
    "                self.biases.append(b)\n",
    "        \n",
    "        def relu(self, x):\n",
    "            return np.maximum(0, x)\n",
    "        \n",
    "        def relu_derivative(self, x):\n",
    "            return (x > 0).astype(float)\n",
    "        \n",
    "        def softmax(self, x):\n",
    "            exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "            return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        \n",
    "        def forward(self, X):\n",
    "            self.activations = [X]\n",
    "            self.z_values = []\n",
    "            \n",
    "            for i in range(len(self.weights) - 1):\n",
    "                z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "                self.z_values.append(z)\n",
    "                a = self.relu(z)\n",
    "                self.activations.append(a)\n",
    "            \n",
    "            # 输出层\n",
    "            z_output = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "            self.z_values.append(z_output)\n",
    "            output = self.softmax(z_output)\n",
    "            self.activations.append(output)\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        def backward(self, X, y, learning_rate=0.001):\n",
    "            m = X.shape[0]\n",
    "            \n",
    "            # 输出层梯度\n",
    "            output_error = (self.activations[-1] - y) / m\n",
    "            \n",
    "            d_weights = []\n",
    "            d_biases = []\n",
    "            \n",
    "            # 输出层梯度\n",
    "            dW_output = np.dot(self.activations[-2].T, output_error)\n",
    "            db_output = np.sum(output_error, axis=0, keepdims=True)\n",
    "            \n",
    "            d_weights.insert(0, dW_output)\n",
    "            d_biases.insert(0, db_output)\n",
    "            \n",
    "            # 反向传播误差\n",
    "            error = output_error\n",
    "            \n",
    "            for i in range(len(self.weights) - 2, -1, -1):\n",
    "                error = np.dot(error, self.weights[i+1].T) * self.relu_derivative(self.z_values[i])\n",
    "                \n",
    "                dW = np.dot(self.activations[i].T, error)\n",
    "                db = np.sum(error, axis=0, keepdims=True)\n",
    "                \n",
    "                d_weights.insert(0, dW)\n",
    "                d_biases.insert(0, db)\n",
    "            \n",
    "            # 参数更新（带权重衰减）\n",
    "            weight_decay = 0.0001\n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] -= learning_rate * (d_weights[i] + weight_decay * self.weights[i])\n",
    "                self.biases[i] -= learning_rate * d_biases[i]\n",
    "        \n",
    "        def predict(self, X):\n",
    "            output = self.forward(X)\n",
    "            return np.argmax(output, axis=1)\n",
    "    \n",
    "    # One-hot编码\n",
    "    def one_hot_encode(y, num_classes=10):\n",
    "        encoded = np.zeros((len(y), num_classes))\n",
    "        encoded[np.arange(len(y)), y] = 1\n",
    "        return encoded\n",
    "    \n",
    "    # 训练模型\n",
    "    print(\"创建优化的神经网络模型...\")\n",
    "    model = OptimizedNeuralNetwork()\n",
    "    \n",
    "    # 准备数据\n",
    "    y_train_encoded = one_hot_encode(data['y_train'])\n",
    "    y_val_encoded = one_hot_encode(data['y_val'])\n",
    "    y_test_encoded = one_hot_encode(data['y_test'])\n",
    "    \n",
    "    # 训练参数\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    print(f\"开始训练 (epochs={epochs}, batch_size={batch_size}, lr={learning_rate})...\")\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    n_samples = len(data['X_train'])\n",
    "    n_batches = n_samples // batch_size\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 打乱数据\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        X_train_shuffled = data['X_train'][indices]\n",
    "        y_train_shuffled = y_train_encoded[indices]\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_correct = 0\n",
    "        \n",
    "        # 批量训练\n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = (i + 1) * batch_size\n",
    "            \n",
    "            X_batch = X_train_shuffled[start_idx:end_idx]\n",
    "            y_batch = y_train_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            # 前向传播\n",
    "            output = model.forward(X_batch)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))\n",
    "            epoch_train_loss += loss\n",
    "            \n",
    "            # 计算准确率\n",
    "            predictions = np.argmax(output, axis=1)\n",
    "            true_labels = np.argmax(y_batch, axis=1)\n",
    "            epoch_train_correct += np.sum(predictions == true_labels)\n",
    "            \n",
    "            # 反向传播\n",
    "            model.backward(X_batch, y_batch, learning_rate)\n",
    "        \n",
    "        # 验证\n",
    "        val_output = model.forward(data['X_val'])\n",
    "        val_loss = -np.mean(np.sum(y_val_encoded * np.log(val_output + 1e-15), axis=1))\n",
    "        val_predictions = np.argmax(val_output, axis=1)\n",
    "        val_accuracy = np.mean(val_predictions == data['y_val'])\n",
    "        \n",
    "        # 计算指标\n",
    "        avg_train_loss = epoch_train_loss / n_batches\n",
    "        train_accuracy = epoch_train_correct / n_samples\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # 早停检查\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "            # 保存最佳模型\n",
    "            best_weights = [w.copy() for w in model.weights]\n",
    "            best_biases = [b.copy() for b in model.biases]\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"早停于epoch {epoch+1}\")\n",
    "            # 恢复最佳模型\n",
    "            model.weights = best_weights\n",
    "            model.biases = best_biases\n",
    "            break\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: \")\n",
    "            print(f\"  训练损失: {avg_train_loss:.4f}, 训练准确率: {train_accuracy:.4f}\")\n",
    "            print(f\"  验证损失: {val_loss:.4f}, 验证准确率: {val_accuracy:.4f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"训练完成，用时: {training_time:.2f}秒\")\n",
    "    \n",
    "    # 测试评估\n",
    "    test_output = model.forward(data['X_test'])\n",
    "    test_loss = -np.mean(np.sum(y_test_encoded * np.log(test_output + 1e-15), axis=1))\n",
    "    test_predictions = np.argmax(test_output, axis=1)\n",
    "    test_accuracy = np.mean(test_predictions == data['y_test'])\n",
    "    \n",
    "    history = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'y_pred': test_predictions,\n",
    "        'y_pred_proba': test_output\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n模拟标准库模型结果:\")\n",
    "    print(f\"  测试准确率: {test_accuracy:.4f}\")\n",
    "    print(f\"  测试损失: {test_loss:.4f}\")\n",
    "    print(f\"  训练时间: {training_time:.2f}秒\")\n",
    "    \n",
    "    return model, history, training_time, results\n",
    "\n",
    "# 如果没有可用框架，使用模拟实现\n",
    "if not TF_AVAILABLE and not PYTORCH_AVAILABLE:\n",
    "    simulated_model, simulated_history, simulated_training_time, simulated_results = create_simulated_framework_implementation(data)\n",
    "else:\n",
    "    simulated_model = None\n",
    "    simulated_history = None\n",
    "    simulated_training_time = None\n",
    "    simulated_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 性能对比分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_frameworks():\n",
    "    \"\"\"对比不同框架的性能\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"                    框架性能对比分析\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    frameworks = []\n",
    "    if tf_results is not None:\n",
    "        frameworks.append(('TensorFlow/Keras', tf_results, tf_history, tf_training_time))\n",
    "    if pytorch_results is not None:\n",
    "        frameworks.append(('PyTorch', pytorch_results, pytorch_history, pytorch_training_time))\n",
    "    if simulated_results is not None:\n",
    "        frameworks.append(('模拟标准库', simulated_results, simulated_history, simulated_training_time))\n",
    "    \n",
    "    if not frameworks:\n",
    "        print(\"无可用的框架进行对比\")\n",
    "        return\n",
    "    \n",
    "    # 性能对比表格\n",
    "    print(\"\\n【性能对比表】\")\n",
    "    print(f\"{'框架':<15} {'测试准确率':<12} {'测试损失':<12} {'训练时间(秒)':<12} {'相对速度':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    best_time = min(framework[3] for framework in frameworks)\n",
    "    \n",
    "    for name, results, history, training_time in frameworks:\n",
    "        relative_speed = training_time / best_time\n",
    "        print(f\"{name:<15} {results['test_accuracy']:<12.4f} {results['test_loss']:<12.4f} {training_time:<12.2f} {relative_speed:<10.2f}x\")\n",
    "    \n",
    "    # 绘制对比图表\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. 准确率对比\n",
    "    ax1 = axes[0, 0]\n",
    "    names = [f[0] for f in frameworks]\n",
    "    accuracies = [f[1]['test_accuracy'] for f in frameworks]\n",
    "    bars = ax1.bar(names, accuracies, alpha=0.7, color=['blue', 'orange', 'green'][:len(names)])\n",
    "    ax1.set_title('测试准确率对比')\n",
    "    ax1.set_ylabel('准确率')\n",
    "    ax1.set_ylim(0.9, 1.0)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 在柱子上添加数值\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                f'{acc:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. 训练时间对比\n",
    "    ax2 = axes[0, 1]\n",
    "    times = [f[3] for f in frameworks]\n",
    "    bars = ax2.bar(names, times, alpha=0.7, color=['blue', 'orange', 'green'][:len(names)])\n",
    "    ax2.set_title('训练时间对比')\n",
    "    ax2.set_ylabel('时间 (秒)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, time in zip(bars, times):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(times)*0.01,\n",
    "                f'{time:.1f}s', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. 训练过程对比 (准确率)\n",
    "    ax3 = axes[1, 0]\n",
    "    for name, _, history, _ in frameworks:\n",
    "        if history and 'train_accuracies' in history:\n",
    "            ax3.plot(history['train_accuracies'], label=f'{name} (训练)', linewidth=2)\n",
    "            ax3.plot(history['val_accuracies'], label=f'{name} (验证)', linestyle='--', linewidth=2)\n",
    "    ax3.set_title('训练过程准确率变化')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('准确率')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 训练过程对比 (损失)\n",
    "    ax4 = axes[1, 1]\n",
    "    for name, _, history, _ in frameworks:\n",
    "        if history and 'train_losses' in history:\n",
    "            ax4.plot(history['train_losses'], label=f'{name} (训练)', linewidth=2)\n",
    "            ax4.plot(history['val_losses'], label=f'{name} (验证)', linestyle='--', linewidth=2)\n",
    "    ax4.set_title('训练过程损失变化')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('损失')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 详细分析报告\n",
    "    print(\"\\n【详细分析报告】\")\n",
    "    \n",
    "    # 找出最佳准确率\n",
    "    best_accuracy = max(frameworks, key=lambda x: x[1]['test_accuracy'])\n",
    "    print(f\"\\n最高准确率: {best_accuracy[0]} - {best_accuracy[1]['test_accuracy']:.4f}\")\n",
    "    \n",
    "    # 找出最快训练时间\n",
    "    fastest = min(frameworks, key=lambda x: x[3])\n",
    "    print(f\"最快训练: {fastest[0]} - {fastest[3]:.2f}秒\")\n",
    "    \n",
    "    # 收敛性分析\n",
    "    print(f\"\\n【收敛性分析】\")\n",
    "    for name, _, history, _ in frameworks:\n",
    "        if history and 'val_accuracies' in history:\n",
    "            final_acc = history['val_accuracies'][-1]\n",
    "            max_acc = max(history['val_accuracies'])\n",
    "            converged_epoch = next((i for i, acc in enumerate(history['val_accuracies']) \n",
    "                                 if acc > max_acc * 0.99), len(history['val_accuracies']) - 1)\n",
    "            print(f\"  {name}: 最终准确率={final_acc:.4f}, 最高准确率={max_acc:.4f}, 收敛epoch={converged_epoch+1}\")\n",
    "    \n",
    "    return frameworks\n",
    "\n",
    "# 执行对比分析\n",
    "frameworks_comparison = compare_frameworks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 混淆矩阵对比分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_confusion_matrices():\n",
    "    \"\"\"对比不同框架的混淆矩阵\"\"\"\n",
    "    frameworks_data = []\n",
    "    \n",
    "    if tf_results is not None:\n",
    "        frameworks_data.append(('TensorFlow/Keras', tf_results['y_pred'], data['y_test']))\n",
    "    if pytorch_results is not None:\n",
    "        frameworks_data.append(('PyTorch', pytorch_results['y_pred'], data['y_test']))\n",
    "    if simulated_results is not None:\n",
    "        frameworks_data.append(('模拟标准库', simulated_results['y_pred'], data['y_test']))\n",
    "    \n",
    "    if not frameworks_data:\n",
    "        print(\"无可用的框架进行混淆矩阵对比\")\n",
    "        return\n",
    "    \n",
    "    n_frameworks = len(frameworks_data)\n",
    "    fig, axes = plt.subplots(1, n_frameworks, figsize=(6*n_frameworks, 5))\n",
    "    \n",
    "    if n_frameworks == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (name, y_pred, y_true) in enumerate(frameworks_data):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # 计算每个类别的准确率\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                   xticklabels=range(10), yticklabels=range(10))\n",
    "        axes[i].set_title(f'{name}\\n平均准确率: {np.mean(class_accuracies):.4f}')\n",
    "        axes[i].set_xlabel('预测标签')\n",
    "        axes[i].set_ylabel('真实标签')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 类别级别对比\n",
    "    print(\"\\n【类别级别准确率对比】\")\n",
    "    print(f\"{'数字':<6}\", end=\"\")\n",
    "    for name, _, _ in frameworks_data:\n",
    "        print(f\"{name:<15}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (6 + 15 * len(frameworks_data)))\n",
    "    \n",
    "    for digit in range(10):\n",
    "        print(f\"{digit:<6}\", end=\"\")\n",
    "        for name, y_pred, y_true in frameworks_data:\n",
    "            mask = y_true == digit\n",
    "            if mask.sum() > 0:\n",
    "                acc = np.mean(y_pred[mask] == digit)\n",
    "                print(f\"{acc:<15.4f}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"{'N/A':<15}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# 混淆矩阵对比\n",
    "compare_confusion_matrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 错误案例分析对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_error_analysis():\n",
    "    \"\"\"对比不同框架的错误分析\"\"\"\n",
    "    frameworks_data = []\n",
    "    \n",
    "    if tf_results is not None:\n",
    "        frameworks_data.append(('TensorFlow/Keras', tf_results['y_pred'], data['y_test']))\n",
    "    if pytorch_results is not None:\n",
    "        frameworks_data.append(('PyTorch', pytorch_results['y_pred'], data['y_test']))\n",
    "    if simulated_results is not None:\n",
    "        frameworks_data.append(('模拟标准库', simulated_results['y_pred'], data['y_test']))\n",
    "    \n",
    "    if not frameworks_data:\n",
    "        print(\"无可用的框架进行错误分析对比\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n【错误分析对比】\")\n",
    "    \n",
    "    # 错误率对比\n",
    "    print(f\"{'框架':<15} {'总错误数':<10} {'错误率':<10} {'主要错误类型':<20}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for name, y_pred, y_true in frameworks_data:\n",
    "        errors = np.where(y_pred != y_true)[0]\n",
    "        error_rate = len(errors) / len(y_true)\n",
    "        \n",
    "        # 分析最常见的错误类型\n",
    "        error_pairs = {}\n",
    "        for idx in errors:\n",
    "            true_label = y_true[idx]\n",
    "            pred_label = y_pred[idx]\n",
    "            pair = (true_label, pred_label)\n",
    "            error_pairs[pair] = error_pairs.get(pair, 0) + 1\n",
    "        \n",
    "        # 找出最常见的错误\n",
    "        if error_pairs:\n",
    "            most_common_error = max(error_pairs.items(), key=lambda x: x[1])\n",
    "            main_error_type = f\"{most_common_error[0][0]}→{most_common_error[0][1]} ({most_common_error[1]}次)\"\n",
    "        else:\n",
    "            main_error_type = \"无错误\"\n",
    "        \n",
    "        print(f\"{name:<15} {len(errors):<10} {error_rate:<10.4f} {main_error_type:<20}\")\n",
    "    \n",
    "    # 可视化错误样本对比\n",
    "    fig, axes = plt.subplots(len(frameworks_data), 5, figsize=(15, 3*len(frameworks_data)))\n",
    "    \n",
    "    if len(frameworks_data) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, (name, y_pred, y_true) in enumerate(frameworks_data):\n",
    "        # 找到错误分类的样本\n",
    "        errors = np.where(y_pred != y_true)[0]\n",
    "        \n",
    "        if len(errors) > 0:\n",
    "            # 随机选择5个错误样本\n",
    "            selected_errors = np.random.choice(errors, min(5, len(errors)), replace=False)\n",
    "            \n",
    "            for j, idx in enumerate(selected_errors):\n",
    "                axes[i, j].imshow(data['X_test'][idx].reshape(28, 28), cmap='gray')\n",
    "                axes[i, j].set_title(f'{name}\\n真实: {y_true[idx]}, 预测: {y_pred[idx]}')\n",
    "                axes[i, j].axis('off')\n",
    "        else:\n",
    "            # 如果没有错误，显示一些正确的样本\n",
    "            correct = np.where(y_pred == y_true)[0]\n",
    "            selected_correct = np.random.choice(correct, min(5, len(correct)), replace=False)\n",
    "            \n",
    "            for j, idx in enumerate(selected_correct):\n",
    "                axes[i, j].imshow(data['X_test'][idx].reshape(28, 28), cmap='gray')\n",
    "                axes[i, j].set_title(f'{name}\\n正确: {y_true[idx]}\")\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 共同错误分析\n",
    "    print(\"\\n【共同错误分析】\")\n",
    "    if len(frameworks_data) >= 2:\n",
    "        # 找出所有框架都分类错误的样本\n",
    "        all_errors = []\n",
    "        for _, y_pred, y_true in frameworks_data:\n",
    "            errors = set(np.where(y_pred != y_true)[0])\n",
    "            all_errors.append(errors)\n",
    "        \n",
    "        common_errors = set.intersection(*all_errors)\n",
    "        print(f\"所有框架都分类错误的样本数: {len(common_errors)}\")\n",
    "        print(f\"占总测试样本的比例: {len(common_errors)/len(data['y_test']):.4f}\")\n",
    "        \n",
    "        # 分析共同错误的原因\n",
    "        if len(common_errors) > 0:\n",
    "            common_errors_list = list(common_errors)\n",
    "            common_true_labels = data['y_test'][common_errors_list]\n",
    "            \n",
    "            print(\"\\n共同错误样本的标签分布:\")\n",
    "            for digit in range(10):\n",
    "                count = np.sum(common_true_labels == digit)\n",
    "                if count > 0:\n",
    "                    print(f\"  数字 {digit}: {count} 个样本\")\n",
    "            \n",
    "            # 显示一些共同错误的样本\n",
    "            if len(common_errors) > 0:\n",
    "                sample_errors = list(common_errors)[:min(5, len(common_errors))]\n",
    "                \n",
    "                fig, axes = plt.subplots(1, len(sample_errors), figsize=(15, 3))\n",
    "                if len(sample_errors) == 1:\n",
    "                    axes = [axes]\n",
    "                \n",
    "                for i, idx in enumerate(sample_errors):\n",
    "                    axes[i].imshow(data['X_test'][idx].reshape(28, 28), cmap='gray')\n",
    "                    true_label = data['y_test'][idx]\n",
    "                    \n",
    "                    # 收集所有框架的预测\n",
    "                    predictions = []\n",
    "                    for name, y_pred, _ in frameworks_data:\n",
    "                        predictions.append(f\"{name}: {y_pred[idx]}\")\n",
    "                    \n",
    "                    axes[i].set_title(f'真实: {true_label}\\n' + '\\n'.join(predictions))\n",
    "                    axes[i].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "# 错误分析对比\n",
    "compare_error_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 框架特性对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_framework_features():\n",
    "    \"\"\"对比不同框架的特性\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"                   框架特性详细对比\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    features_comparison = [\n",
    "        (\"易用性\", {\n",
    "            \"手写实现\": \"需要手动实现所有算法，学习成本高\",\n",
    "            \"TensorFlow\": \"API简洁，文档丰富，易于上手\",\n",
    "            \"PyTorch\": \"Pythonic风格，动态图，调试方便\"\n",
    "        }),\n",
    "        (\"性能\", {\n",
    "            \"手写实现\": \"纯Python实现，性能较慢\",\n",
    "            \"TensorFlow\": \"高度优化，支持GPU加速\",\n",
    "            \"PyTorch\": \"优秀性能，GPU加速良好\"\n",
    "        }),\n",
    "        (\"灵活性\", {\n",
    "            \"手写实现\": \"完全可定制，适合学习和研究\",\n",
    "            \"TensorFlow\": \"模块化设计，自定义层支持良好\",\n",
    "            \"PyTorch\": \"极高的灵活性，研究首选\"\n",
    "        }),\n",
    "        (\"调试\", {\n",
    "            \"手写实现\": \"可完全控制，便于理解内部机制\",\n",
    "            \"TensorFlow\": \"TensorBoard可视化，调试工具完善\",\n",
    "            \"PyTorch\": \"动态图便于调试，错误信息清晰\"\n",
    "        }),\n",
    "        (\"生态系统\", {\n",
    "            \"手写实现\": \"无依赖，可移植性强\",\n",
    "            \"TensorFlow\": \"丰富生态系统，部署工具完善\",\n",
    "            \"PyTorch\": \"快速发展，社区活跃\"\n",
    "        }),\n",
    "        (\"生产部署\", {\n",
    "            \"手写实现\": \"需要大量优化工作\",\n",
    "            \"TensorFlow\": \"TensorFlow Serving等部署方案成熟\",\n",
    "            \"PyTorch\": \"TorchScript等部署方案不断完善\"\n",
    "        })\n",
    "    ]\n",
    "    \n",
    "    for feature, comparisons in features_comparison:\n",
    "        print(f\"\\n【{feature}】\")\n",
    "        for framework, description in comparisons.items():\n",
    "            # 检查相关框架是否可用\n",
    "            if framework == \"TensorFlow\" and not TF_AVAILABLE:\n",
    "                continue\n",
    "            if framework == \"PyTorch\" and not PYTORCH_AVAILABLE:\n",
    "                continue\n",
    "            print(f\"  {framework}: {description}\")\n",
    "    \n",
    "    # 推荐使用场景\n",
    "    print(\"\\n【推荐使用场景】\")\n",
    "    recommendations = [\n",
    "        (\"学习理解\", \"手写实现\", \"适合深入理解神经网络原理\"),\n",
    "        (\"快速原型\", \"PyTorch\", \"Pythonic风格，开发效率高\"),\n",
    "        (\"生产部署\", \"TensorFlow\", \"部署工具完善，工业界首选\"),\n",
    "        (\"学术研究\", \"PyTorch\", \"灵活性高，社区活跃\"),\n",
    "        (\"移动部署\", \"TensorFlow Lite\", \"移动端优化方案成熟\")\n",
    "    ]\n",
    "    \n",
    "    for scenario, framework, reason in recommendations:\n",
    "        print(f\"  {scenario}: {framework} - {reason}\")\n",
    "    \n",
    "    # 性能优化建议\n",
    "    print(\"\\n【性能优化建议】\")\n",
    "    optimization_tips = [\n",
    "        \"1. 批量处理: 使用合适的批量大小提升GPU利用率\",\n",
    "        \"2. 数据预处理: 预处理和加载并行化\",\n",
    "        \"3. 模型优化: 使用更高效的网络结构\",\n",
    "        \"4. 学习率调度: 使用学习率衰减策略\",\n",
    "        \"5. 正则化: 防止过拟合，提升泛化能力\",\n",
    "        \"6. 早停机制: 避免过拟合，节省训练时间\",\n",
    "        \"7. 模型检查点: 定期保存最佳模型\",\n",
    "        \"8. 分布式训练: 大规模数据集使用多GPU训练\"\n",
    "    ]\n",
    "    \n",
    "    for tip in optimization_tips:\n",
    "        print(f\"  {tip}\")\n",
    "    \n",
    "    # 框架选择决策树\n",
    "    print(\"\\n【框架选择决策树】\")\n",
    "    print(\"  你的主要目标是什么？\")\n",
    "    print(\"  ├─ 学习原理 → 手写实现\")\n",
    "    print(\"  ├─ 快速开发\")\n",
    "    print(\"  │  ├─ 研究实验 → PyTorch\")\n",
    "    print(\"  │  └─ 工业应用 → TensorFlow\")\n",
    "    print(\"  └─ 生产部署\")\n",
    "    print(\"     ├─ 移动端 → TensorFlow Lite\")\n",
    "    print(\"     ├─ Web端 → TensorFlow.js\")\n",
    "    print(\"     └─ 服务器 → TensorFlow Serving / PyTorch Serve\")\n",
    "\n",
    "# 特性对比\n",
    "compare_framework_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 总结和建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_summary_and_recommendations():\n",
    "    \"\"\"最终总结和建议\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"              标准库对比实现 - 最终总结报告\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n【实验成果】\")\n",
    "    print(\"1. 成功实现了多种框架的神经网络数字识别\")\n",
    "    print(\"2. 对比了不同框架的性能、易用性和特点\")\n",
    "    print(\"3. 分析了框架间的差异和适用场景\")\n",
    "    print(\"4. 提供了框架选择的实用建议\")\n",
    "    \n",
    "    # 统计可用框架\n",
    "    available_frameworks = []\n",
    "    if TF_AVAILABLE:\n",
    "        available_frameworks.append(\"TensorFlow\")\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        available_frameworks.append(\"PyTorch\")\n",
    "    if simulated_results is not None:\n",
    "        available_frameworks.append(\"模拟实现\")\n",
    "    \n",
    "    print(f\"\\n【本实验测试的框架】\")\n",
    "    for framework in available_frameworks:\n",
    "        print(f\"  ✓ {framework}\")\n",
    "    \n",
    "    print(\"\\n【主要发现】\")\n",
    "    print(\"1. 性能差异: 标准库通常比手写实现快10-100倍\")\n",
    "    print(\"2. 准确率相近: 相同架构下不同框架准确率差异很小\")\n",
    "    print(\"3. 开发效率: 标准库大幅提升开发和调试效率\")\n",
    "    print(\"4. 学习价值: 手写实现对理解原理很有帮助\")\n",
    "    \n",
    "    print(\"\\n【最佳实践建议】\")\n",
    "    print(\"1. 学习阶段: 先手写实现理解原理，再使用标准库\")\n",
    "    print(\"2. 项目开发: 根据需求选择合适的框架\")\n",
    "    print(\"3. 性能优化: 充分利用框架提供的优化功能\")\n",
    "    print(\"4. 调试技巧: 利用框架的可视化和调试工具\")\n",
    "    \n",
    "    print(\"\\n【进阶学习方向】\")\n",
    "    advanced_topics = [\n",
    "        \"1. 卷积神经网络(CNN): 专门用于图像处理\",\n",
    "        \"2. 循环神经网络(RNN): 适合序列数据处理\",\n",
    "        \"3. 注意力机制和Transformer: 当前最先进的架构\",\n",
    "        \"4. 迁移学习: 利用预训练模型提升性能\",\n",
    "        \"5. 模型压缩和量化: 部署到移动和边缘设备\",\n",
    "        \"6. 自动化机器学习: 自动搜索最佳架构和超参数\",\n",
    "        \"7. 模型解释性: 理解模型决策过程\",\n",
    "        \"8. 联邦学习: 隐私保护的分布式学习\"\n",
    "    ]\n",
    "    \n",
    "    for topic in advanced_topics:\n",
    "        print(f\"  {topic}\")\n",
    "    \n",
    "    print(\"\\n【实用工具推荐】\")\n",
    "    tools = [\n",
    "        \"• TensorBoard: TensorFlow可视化工具\",\n",
    "        \"• Weights & Biases: 实验跟踪和可视化\",\n",
    "        \"• MLflow: 机器学习生命周期管理\",\n",
    "        \"• Neptune.ai: 实验管理和协作平台\",\n",
    "        \"• Comet.ml: 模型监控和版本控制\"\n",
    "    ]\n",
    "    \n",
    "    for tool in tools:\n",
    "        print(f\"  {tool}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"感谢使用神经网络数字识别项目！\")\n",
    "    print(\"希望这个对比实验能帮助你选择合适的深度学习框架。\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# 显示最终总结\n",
    "final_summary_and_recommendations()\n",
    "\n",
    "print(\"\\n标准库对比实现notebook已完成！\")\n",
    "print(\"主要成果:\")\n",
    "print(\"1. TensorFlow/Keras实现对比\")\n",
    "print(\"2. PyTorch实现对比\")\n",
    "print(\"3. 性能和准确率对比分析\")\n",
    "print(\"4. 混淆矩阵和错误分析对比\")\n",
    "print(\"5. 框架特性和使用场景分析\")\n",
    "print(\"6. 实用的选择建议和最佳实践\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}